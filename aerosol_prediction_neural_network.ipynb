{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aerosol Prediction Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Caracterization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 10\n",
      "Number of instances: 10438\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>elevation</th>\n",
       "      <th>ozone</th>\n",
       "      <th>NO2</th>\n",
       "      <th>azimuth</th>\n",
       "      <th>zenith</th>\n",
       "      <th>incidence_azimuth</th>\n",
       "      <th>incidence_zenith</th>\n",
       "      <th>file_name_l1</th>\n",
       "      <th>value_550</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>318</td>\n",
       "      <td>0.248</td>\n",
       "      <td>150.6</td>\n",
       "      <td>31.8</td>\n",
       "      <td>286.1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>AAOT_45-3139_12-5083_COPERNICUS_S2_20180807T10...</td>\n",
       "      <td>0.277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>302</td>\n",
       "      <td>0.279</td>\n",
       "      <td>161.6</td>\n",
       "      <td>44.2</td>\n",
       "      <td>243.6</td>\n",
       "      <td>3.9</td>\n",
       "      <td>AAOT_45-3139_12-5083_COPERNICUS_S2_20180916T10...</td>\n",
       "      <td>0.201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>373</td>\n",
       "      <td>0.303</td>\n",
       "      <td>163.5</td>\n",
       "      <td>34.4</td>\n",
       "      <td>103.9</td>\n",
       "      <td>9.8</td>\n",
       "      <td>AAOT_45-3139_12-5083_COPERNICUS_S2_20190421T10...</td>\n",
       "      <td>0.169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>342</td>\n",
       "      <td>0.271</td>\n",
       "      <td>144.7</td>\n",
       "      <td>25.3</td>\n",
       "      <td>286.2</td>\n",
       "      <td>7.9</td>\n",
       "      <td>AAOT_45-3139_12-5083_COPERNICUS_S2_20190623T10...</td>\n",
       "      <td>0.107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>327</td>\n",
       "      <td>0.252</td>\n",
       "      <td>140.4</td>\n",
       "      <td>29.4</td>\n",
       "      <td>105.8</td>\n",
       "      <td>7.0</td>\n",
       "      <td>AAOT_45-3139_12-5083_COPERNICUS_S2_20190720T10...</td>\n",
       "      <td>0.188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  elevation  ozone    NO2  azimuth  zenith  incidence_azimuth  \\\n",
       "0   1         10    318  0.248    150.6    31.8              286.1   \n",
       "1   2         10    302  0.279    161.6    44.2              243.6   \n",
       "2   4         10    373  0.303    163.5    34.4              103.9   \n",
       "3   5         10    342  0.271    144.7    25.3              286.2   \n",
       "4   6         10    327  0.252    140.4    29.4              105.8   \n",
       "\n",
       "   incidence_zenith                                       file_name_l1  \\\n",
       "0               8.0  AAOT_45-3139_12-5083_COPERNICUS_S2_20180807T10...   \n",
       "1               3.9  AAOT_45-3139_12-5083_COPERNICUS_S2_20180916T10...   \n",
       "2               9.8  AAOT_45-3139_12-5083_COPERNICUS_S2_20190421T10...   \n",
       "3               7.9  AAOT_45-3139_12-5083_COPERNICUS_S2_20190623T10...   \n",
       "4               7.0  AAOT_45-3139_12-5083_COPERNICUS_S2_20190720T10...   \n",
       "\n",
       "   value_550  \n",
       "0      0.277  \n",
       "1      0.201  \n",
       "2      0.169  \n",
       "3      0.107  \n",
       "4      0.188  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"datasets/train.csv\")\n",
    "\n",
    "print(f'Number of features: {df.shape[1]}')\n",
    "print(f'Number of instances: {df.shape[0]}')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the dataset is composed of 10 features and has 10438 instances or observations.\n",
    "\n",
    "The target feature is the 'value_550', the one we want to be capable of predicting.\n",
    "\n",
    "Then we can split the features into two groups, the numeric features, and the image feature. The features, 'id' (identification feature, is not important for the training and prediction), 'elevation', 'ozone', 'NO2', 'azimuth', 'zenith', 'incidence_azimuth', and 'incident_zenith' are the numeric features, that will be scaled for a better Neural Network Model training. At last, but not least, the feature file_name_l1 is the name associated to the image from the zone where the other features where measured."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data separation (numerical and images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import os\n",
    "import tifffile as tiff\n",
    "\n",
    "# Preprocess numerical data\n",
    "numerical_features = df[['elevation', 'ozone', 'NO2', 'azimuth', 'zenith', 'incidence_azimuth', 'incidence_zenith']]\n",
    "\n",
    "# Numerical data scaling\n",
    "scaler = StandardScaler()\n",
    "numerical_features = scaler.fit_transform(numerical_features)\n",
    "\n",
    "# Function to load and preprocess image data\n",
    "def load_and_preprocess_image(filepath):\n",
    "    img = tiff.imread(filepath)\n",
    "    img_array = np.array(img)\n",
    "    img_array = img_array / 65535.0   # Normalize pixel values\n",
    "    return img_array\n",
    "\n",
    "# Load image data\n",
    "image_data = np.array([load_and_preprocess_image(os.path.join('./train/', filename)) for filename in df['file_name_l1']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Target variable\n",
    "target = df['value_550'].values\n",
    "\n",
    "# Split data into training, validation, and testing sets\n",
    "X_train_num, X_temp_num, X_train_img, X_temp_img, y_train, y_temp = train_test_split(numerical_features, image_data, target, test_size=0.3, random_state=42)\n",
    "X_val_num, X_test_num, X_val_img, X_test_img, y_val, y_test = train_test_split(X_temp_num, X_temp_img, y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Arquitecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Input, Concatenate, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# Define the CNN and dense model\n",
    "class AOTModel:\n",
    "    def __init__(self, image_shape=(19, 19, 13), num_numerical_features=7):\n",
    "        # Image processing Neural Network\n",
    "        self.image_input = Input(shape=image_shape)\n",
    "        image_processing_network = Conv2D(32, (3, 3), activation='relu', kernel_regularizer=l2(0.01))(self.image_input)\n",
    "        image_processing_network = BatchNormalization()(image_processing_network)\n",
    "        image_processing_network = MaxPooling2D((2, 2))(image_processing_network)\n",
    "        image_processing_network = Dropout(0.25)(image_processing_network)\n",
    "\n",
    "        image_processing_network = Conv2D(64, (3, 3), activation='relu', kernel_regularizer=l2(0.01))(image_processing_network)\n",
    "        image_processing_network = BatchNormalization()(image_processing_network)\n",
    "        image_processing_network = MaxPooling2D((2, 2))(image_processing_network)\n",
    "        image_processing_network = Dropout(0.25)(image_processing_network)\n",
    "\n",
    "        image_processing_network = Conv2D(128, (3, 3), activation='relu', kernel_regularizer=l2(0.01))(image_processing_network)\n",
    "        image_processing_network = BatchNormalization()(image_processing_network)\n",
    "        image_processing_network = GlobalAveragePooling2D()(image_processing_network)\n",
    "        image_processing_network = Dropout(0.5)(image_processing_network)\n",
    "\n",
    "        # Numerical processing Neural Network\n",
    "        self.numerical_input = Input(shape=(num_numerical_features,))\n",
    "        numerical_processing_network = Dense(128, activation='relu')(self.numerical_input)\n",
    "        numerical_processing_network = BatchNormalization()(numerical_processing_network)\n",
    "        numerical_processing_network = Dropout(0.5)(numerical_processing_network)\n",
    "        \n",
    "        numerical_processing_network = Dense(64, activation='relu')(numerical_processing_network)\n",
    "        numerical_processing_network = BatchNormalization()(numerical_processing_network)\n",
    "        numerical_processing_network = Dropout(0.5)(numerical_processing_network)\n",
    "\n",
    "        numerical_processing_network = Dense(32, activation='relu')(numerical_processing_network)\n",
    "        numerical_processing_network = BatchNormalization()(numerical_processing_network)\n",
    "        numerical_processing_network = Dropout(0.5)(numerical_processing_network)\n",
    "        \n",
    "        # Concatenation of both networks\n",
    "        aot_network = Concatenate()([image_processing_network, numerical_processing_network])\n",
    "        aot_network = Dense(64, activation='relu')(aot_network)\n",
    "        aot_network = Dropout(0.5)(aot_network)\n",
    "        aot_network = Dense(1)(aot_network)\n",
    "\n",
    "        self.aot_network_arquitecture = aot_network\n",
    "        del image_processing_network, numerical_processing_network, aot_network\n",
    "\n",
    "    def model(self):\n",
    "        model = Model(inputs= [self.image_input, self.numerical_input], outputs=self.aot_network_arquitecture)\n",
    "        # Compile the model\n",
    "        model.compile(optimizer='adam', loss='mean_absolute_error', metrics=['mae'])\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1718973122.119512  639635 service.cc:145] XLA service 0x7fa77c004ee0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1718973122.119570  639635 service.cc:153]   StreamExecutor device (0): NVIDIA TITAN V, Compute Capability 7.0\n",
      "I0000 00:00:1718973122.119639  639635 service.cc:153]   StreamExecutor device (1): NVIDIA TITAN V, Compute Capability 7.0\n",
      "2024-06-21 13:32:02.377789: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-06-21 13:32:03.306926: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 23/229\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 3.1535 - mae: 1.7062"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1718973141.213018  639635 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 94ms/step - loss: 2.5949 - mae: 1.2511 - val_loss: 1.1313 - val_mae: 0.1219 - learning_rate: 0.0010\n",
      "Epoch 2/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 1.3125 - mae: 0.4073 - val_loss: 0.7208 - val_mae: 0.0975 - learning_rate: 0.0010\n",
      "Epoch 3/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.7061 - mae: 0.1580 - val_loss: 0.4492 - val_mae: 0.0911 - learning_rate: 0.0010\n",
      "Epoch 4/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.4044 - mae: 0.0917 - val_loss: 0.2917 - val_mae: 0.0898 - learning_rate: 0.0010\n",
      "Epoch 5/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.2638 - mae: 0.0871 - val_loss: 0.2060 - val_mae: 0.0894 - learning_rate: 0.0010\n",
      "Epoch 6/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1899 - mae: 0.0865 - val_loss: 0.1584 - val_mae: 0.0862 - learning_rate: 0.0010\n",
      "Epoch 7/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1481 - mae: 0.0834 - val_loss: 0.1413 - val_mae: 0.0950 - learning_rate: 0.0010\n",
      "Epoch 8/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1245 - mae: 0.0821 - val_loss: 0.1243 - val_mae: 0.0922 - learning_rate: 0.0010\n",
      "Epoch 9/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1118 - mae: 0.0820 - val_loss: 0.1340 - val_mae: 0.1119 - learning_rate: 0.0010\n",
      "Epoch 10/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1048 - mae: 0.0836 - val_loss: 0.1500 - val_mae: 0.1326 - learning_rate: 0.0010\n",
      "Epoch 11/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0953 - mae: 0.0784 - val_loss: 0.0946 - val_mae: 0.0802 - learning_rate: 0.0010\n",
      "Epoch 12/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0977 - mae: 0.0835 - val_loss: 0.1000 - val_mae: 0.0879 - learning_rate: 0.0010\n",
      "Epoch 13/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0925 - mae: 0.0804 - val_loss: 0.0936 - val_mae: 0.0833 - learning_rate: 0.0010\n",
      "Epoch 14/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0950 - mae: 0.0840 - val_loss: 0.1015 - val_mae: 0.0909 - learning_rate: 0.0010\n",
      "Epoch 15/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0900 - mae: 0.0808 - val_loss: 0.0993 - val_mae: 0.0918 - learning_rate: 0.0010\n",
      "Epoch 16/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0885 - mae: 0.0803 - val_loss: 0.0870 - val_mae: 0.0790 - learning_rate: 0.0010\n",
      "Epoch 17/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0855 - mae: 0.0782 - val_loss: 0.1013 - val_mae: 0.0936 - learning_rate: 0.0010\n",
      "Epoch 18/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0863 - mae: 0.0788 - val_loss: 0.0842 - val_mae: 0.0775 - learning_rate: 0.0010\n",
      "Epoch 19/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0844 - mae: 0.0783 - val_loss: 0.0891 - val_mae: 0.0831 - learning_rate: 0.0010\n",
      "Epoch 20/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0869 - mae: 0.0810 - val_loss: 0.0928 - val_mae: 0.0877 - learning_rate: 0.0010\n",
      "Epoch 21/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0832 - mae: 0.0776 - val_loss: 0.0871 - val_mae: 0.0825 - learning_rate: 0.0010\n",
      "Epoch 22/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0823 - mae: 0.0774 - val_loss: 0.0884 - val_mae: 0.0830 - learning_rate: 0.0010\n",
      "Epoch 23/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0831 - mae: 0.0777 - val_loss: 0.0826 - val_mae: 0.0779 - learning_rate: 0.0010\n",
      "Epoch 24/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0828 - mae: 0.0780 - val_loss: 0.0950 - val_mae: 0.0906 - learning_rate: 0.0010\n",
      "Epoch 25/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0815 - mae: 0.0771 - val_loss: 0.0960 - val_mae: 0.0915 - learning_rate: 0.0010\n",
      "Epoch 26/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0814 - mae: 0.0768 - val_loss: 0.0845 - val_mae: 0.0793 - learning_rate: 0.0010\n",
      "Epoch 27/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0805 - mae: 0.0753 - val_loss: 0.0928 - val_mae: 0.0885 - learning_rate: 0.0010\n",
      "Epoch 28/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0813 - mae: 0.0769 - val_loss: 0.0852 - val_mae: 0.0809 - learning_rate: 0.0010\n",
      "Epoch 29/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0794 - mae: 0.0755 - val_loss: 0.0785 - val_mae: 0.0751 - learning_rate: 5.0000e-04\n",
      "Epoch 30/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0752 - mae: 0.0719 - val_loss: 0.0789 - val_mae: 0.0757 - learning_rate: 5.0000e-04\n",
      "Epoch 31/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0760 - mae: 0.0728 - val_loss: 0.0879 - val_mae: 0.0845 - learning_rate: 5.0000e-04\n",
      "Epoch 32/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0797 - mae: 0.0764 - val_loss: 0.0751 - val_mae: 0.0720 - learning_rate: 5.0000e-04\n",
      "Epoch 33/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0759 - mae: 0.0727 - val_loss: 0.0878 - val_mae: 0.0845 - learning_rate: 5.0000e-04\n",
      "Epoch 34/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0736 - mae: 0.0704 - val_loss: 0.0977 - val_mae: 0.0944 - learning_rate: 5.0000e-04\n",
      "Epoch 35/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0757 - mae: 0.0725 - val_loss: 0.0927 - val_mae: 0.0895 - learning_rate: 5.0000e-04\n",
      "Epoch 36/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0743 - mae: 0.0711 - val_loss: 0.0829 - val_mae: 0.0797 - learning_rate: 5.0000e-04\n",
      "Epoch 37/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0780 - mae: 0.0747 - val_loss: 0.1466 - val_mae: 0.1433 - learning_rate: 5.0000e-04\n",
      "Epoch 38/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0740 - mae: 0.0709 - val_loss: 0.0716 - val_mae: 0.0688 - learning_rate: 2.5000e-04\n",
      "Epoch 39/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0753 - mae: 0.0725 - val_loss: 0.0750 - val_mae: 0.0722 - learning_rate: 2.5000e-04\n",
      "Epoch 40/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0720 - mae: 0.0693 - val_loss: 0.0817 - val_mae: 0.0790 - learning_rate: 2.5000e-04\n",
      "Epoch 41/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0754 - mae: 0.0727 - val_loss: 0.0711 - val_mae: 0.0685 - learning_rate: 2.5000e-04\n",
      "Epoch 42/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0758 - mae: 0.0732 - val_loss: 0.0751 - val_mae: 0.0726 - learning_rate: 2.5000e-04\n",
      "Epoch 43/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0737 - mae: 0.0712 - val_loss: 0.0685 - val_mae: 0.0659 - learning_rate: 2.5000e-04\n",
      "Epoch 44/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0742 - mae: 0.0717 - val_loss: 0.0827 - val_mae: 0.0802 - learning_rate: 2.5000e-04\n",
      "Epoch 45/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0710 - mae: 0.0685 - val_loss: 0.0817 - val_mae: 0.0792 - learning_rate: 2.5000e-04\n",
      "Epoch 46/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0707 - mae: 0.0683 - val_loss: 0.0750 - val_mae: 0.0724 - learning_rate: 2.5000e-04\n",
      "Epoch 47/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0713 - mae: 0.0688 - val_loss: 0.0742 - val_mae: 0.0717 - learning_rate: 2.5000e-04\n",
      "Epoch 48/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0733 - mae: 0.0708 - val_loss: 0.0882 - val_mae: 0.0857 - learning_rate: 2.5000e-04\n",
      "Epoch 49/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0749 - mae: 0.0723 - val_loss: 0.0829 - val_mae: 0.0805 - learning_rate: 1.2500e-04\n",
      "Epoch 50/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0709 - mae: 0.0685 - val_loss: 0.0776 - val_mae: 0.0753 - learning_rate: 1.2500e-04\n",
      "Epoch 51/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0711 - mae: 0.0687 - val_loss: 0.0686 - val_mae: 0.0662 - learning_rate: 1.2500e-04\n",
      "Epoch 52/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0681 - mae: 0.0657 - val_loss: 0.0964 - val_mae: 0.0940 - learning_rate: 1.2500e-04\n",
      "Epoch 53/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0718 - mae: 0.0695 - val_loss: 0.0688 - val_mae: 0.0665 - learning_rate: 1.2500e-04\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0698 - mae: 0.0673\n",
      "Validation MAE: 0.06594149768352509\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0621 - mae: 0.0596\n",
      "Test MAE: 0.06330402195453644\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Instantiate the model\n",
    "model = AOTModel()\n",
    "model = model.model()\n",
    "\n",
    "# Define callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    [X_train_img, X_train_num], y_train,\n",
    "    validation_data=([X_val_img, X_val_num], y_val),\n",
    "    epochs=200,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "model.save('aot_model.keras')\n",
    "\n",
    "# Evaluate the model\n",
    "val_loss, val_mae = model.evaluate([X_val_img, X_val_num], y_val)\n",
    "print(f'Validation MAE: {val_mae}')\n",
    "\n",
    "# Evaluate on test set\n",
    "test_loss, test_mae = model.evaluate([X_test_img, X_test_num], y_test)\n",
    "print(f'Test MAE: {test_mae}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step\n",
      "   id  value_550\n",
      "0   3   0.111323\n",
      "1  25   0.193926\n",
      "2  26   0.119942\n",
      "3  27   0.109297\n",
      "4  29   0.123382\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the saved model\n",
    "model = load_model('aot_model.h5')\n",
    "\n",
    "# Load the new dataset\n",
    "new_df = pd.read_csv(\"datasets/test.csv\")\n",
    "\n",
    "# Preprocess numerical data\n",
    "new_numerical_features = new_df[['elevation', 'ozone', 'NO2', 'azimuth', 'zenith', 'incidence_azimuth', 'incidence_zenith']]\n",
    "new_numerical_features = scaler.transform(new_numerical_features)\n",
    "\n",
    "# Load and preprocess new image data\n",
    "new_image_data = np.array([load_and_preprocess_image(os.path.join('./test/', filename)) for filename in new_df['file_name_l1']])\n",
    "\n",
    "# Predict values for the new data\n",
    "predictions = model.predict([new_image_data, new_numerical_features])\n",
    "\n",
    "# Save the predictions to a CSV file\n",
    "results = pd.DataFrame({\n",
    "    'id': new_df['id'],\n",
    "    'value_550': predictions.flatten()\n",
    "})\n",
    "results.to_csv('predictions.csv', index=False)\n",
    "\n",
    "print(results.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
