{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aerosol Prediction Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Caracterization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 10\n",
      "Number of instances: 10438\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>elevation</th>\n",
       "      <th>ozone</th>\n",
       "      <th>NO2</th>\n",
       "      <th>azimuth</th>\n",
       "      <th>zenith</th>\n",
       "      <th>incidence_azimuth</th>\n",
       "      <th>incidence_zenith</th>\n",
       "      <th>file_name_l1</th>\n",
       "      <th>value_550</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>318</td>\n",
       "      <td>0.248</td>\n",
       "      <td>150.6</td>\n",
       "      <td>31.8</td>\n",
       "      <td>286.1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>AAOT_45-3139_12-5083_COPERNICUS_S2_20180807T10...</td>\n",
       "      <td>0.277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>302</td>\n",
       "      <td>0.279</td>\n",
       "      <td>161.6</td>\n",
       "      <td>44.2</td>\n",
       "      <td>243.6</td>\n",
       "      <td>3.9</td>\n",
       "      <td>AAOT_45-3139_12-5083_COPERNICUS_S2_20180916T10...</td>\n",
       "      <td>0.201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>373</td>\n",
       "      <td>0.303</td>\n",
       "      <td>163.5</td>\n",
       "      <td>34.4</td>\n",
       "      <td>103.9</td>\n",
       "      <td>9.8</td>\n",
       "      <td>AAOT_45-3139_12-5083_COPERNICUS_S2_20190421T10...</td>\n",
       "      <td>0.169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>342</td>\n",
       "      <td>0.271</td>\n",
       "      <td>144.7</td>\n",
       "      <td>25.3</td>\n",
       "      <td>286.2</td>\n",
       "      <td>7.9</td>\n",
       "      <td>AAOT_45-3139_12-5083_COPERNICUS_S2_20190623T10...</td>\n",
       "      <td>0.107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>327</td>\n",
       "      <td>0.252</td>\n",
       "      <td>140.4</td>\n",
       "      <td>29.4</td>\n",
       "      <td>105.8</td>\n",
       "      <td>7.0</td>\n",
       "      <td>AAOT_45-3139_12-5083_COPERNICUS_S2_20190720T10...</td>\n",
       "      <td>0.188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  elevation  ozone    NO2  azimuth  zenith  incidence_azimuth  \\\n",
       "0   1         10    318  0.248    150.6    31.8              286.1   \n",
       "1   2         10    302  0.279    161.6    44.2              243.6   \n",
       "2   4         10    373  0.303    163.5    34.4              103.9   \n",
       "3   5         10    342  0.271    144.7    25.3              286.2   \n",
       "4   6         10    327  0.252    140.4    29.4              105.8   \n",
       "\n",
       "   incidence_zenith                                       file_name_l1  \\\n",
       "0               8.0  AAOT_45-3139_12-5083_COPERNICUS_S2_20180807T10...   \n",
       "1               3.9  AAOT_45-3139_12-5083_COPERNICUS_S2_20180916T10...   \n",
       "2               9.8  AAOT_45-3139_12-5083_COPERNICUS_S2_20190421T10...   \n",
       "3               7.9  AAOT_45-3139_12-5083_COPERNICUS_S2_20190623T10...   \n",
       "4               7.0  AAOT_45-3139_12-5083_COPERNICUS_S2_20190720T10...   \n",
       "\n",
       "   value_550  \n",
       "0      0.277  \n",
       "1      0.201  \n",
       "2      0.169  \n",
       "3      0.107  \n",
       "4      0.188  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"datasets/train.csv\")\n",
    "\n",
    "print(f'Number of features: {df.shape[1]}')\n",
    "print(f'Number of instances: {df.shape[0]}')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the dataset is composed of 10 features and has 10438 instances or observations.\n",
    "\n",
    "The target feature is the 'value_550', the one we want to be capable of predicting.\n",
    "\n",
    "Then we can split the features into two groups, the numeric features, and the image feature. The features, 'id' (identification feature, is not important for the training and prediction), 'elevation', 'ozone', 'NO2', 'azimuth', 'zenith', 'incidence_azimuth', and 'incident_zenith' are the numeric features, that will be scaled for a better Neural Network Model training. At last, but not least, the feature file_name_l1 is the name associated to the image from the zone where the other features where measured."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data separation (numerical and images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-13 01:53:58.626733: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-13 01:54:00.122334: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.api.utils import load_img, img_to_array\n",
    "import numpy as np\n",
    "import os\n",
    "import tifffile as tiff\n",
    "\n",
    "# Preprocess numerical data\n",
    "numerical_features = df[['elevation', 'ozone', 'NO2', 'azimuth', 'zenith', 'incidence_azimuth', 'incidence_zenith']]\n",
    "\n",
    "# Numerical data scaling\n",
    "scaler = StandardScaler()\n",
    "# Applying the scaler to the values\n",
    "numerical_features = scaler.fit_transform(numerical_features)\n",
    "\n",
    "# Function to load and preprocess image data\n",
    "def load_and_preprocess_image(filepath):\n",
    "    img = tiff.imread(filepath)  # Resize images to a fixed size\n",
    "    img_array = np.array(img)\n",
    "    img_array = img_array / 255.0  # Normalize pixel values\n",
    "    return img_array\n",
    "\n",
    "image_data = np.array([load_and_preprocess_image(os.path.join('./train/', filename)) for filename in df['file_name_l1']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Target variable\n",
    "target = df['value_550'].values\n",
    "\n",
    "#Split data into training and validation sets\n",
    "X_train_num, X_val_num, X_train_img, X_val_img, y_train, y_val = train_test_split(numerical_features, image_data, target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Arquitecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Input, Concatenate\n",
    "\n",
    "# class AOTModel:\n",
    "#     def __init__(self, image_shape=(128, 128, 3), num_numerical_features=7):\n",
    "#         self.image_shape = image_shape\n",
    "#         self.num_numerical_features = num_numerical_features\n",
    "#         self.model = self.build_model()\n",
    "        \n",
    "#     def build_model(self):\n",
    "#         # Define CNN for image data\n",
    "#         image_input = Input(shape=self.image_shape)\n",
    "#         x = Conv2D(32, (3, 3), activation='relu')(image_input)\n",
    "#         x = MaxPooling2D((2, 2))(x)\n",
    "#         x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "#         x = MaxPooling2D((2, 2))(x)\n",
    "#         x = Flatten()(x)\n",
    "#         x = Dense(64, activation='relu')(x)\n",
    "\n",
    "#         # Define feedforward network for numerical data\n",
    "#         numerical_input = Input(shape=(self.num_numerical_features,))\n",
    "#         y = Dense(64, activation='relu')(numerical_input)\n",
    "#         y = Dense(64, activation='relu')(y)\n",
    "\n",
    "#         # Concatenate outputs of both networks\n",
    "#         combined = Concatenate()([x, y])\n",
    "#         z = Dense(64, activation='relu')(combined)\n",
    "#         output = Dense(1)(z)\n",
    "\n",
    "#         # Define the model\n",
    "#         model = Model(inputs=[image_input, numerical_input], outputs=output)\n",
    "\n",
    "#         # Compile the model\n",
    "#         model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "        \n",
    "#         return model\n",
    "    \n",
    "class AOTModel:\n",
    "    def __init__(self, image_shape=(19, 19, 3), num_numerical_features=7):\n",
    "\n",
    "        # Image processing Neural Network\n",
    "        self.image_input = Input(shape=image_shape)\n",
    "        image_processing_network = Conv2D(32, (3, 3), activation='relu')(self.image_input)\n",
    "        image_processing_network = MaxPooling2D((2, 2))(image_processing_network)\n",
    "        image_processing_network = Conv2D(64, (3, 3), activation='relu')(image_processing_network)\n",
    "        image_processing_network = MaxPooling2D((2, 2))(image_processing_network)\n",
    "        image_processing_network = Flatten()(image_processing_network)\n",
    "        image_processing_network = Dense(64, activation='relu')(image_processing_network)\n",
    "\n",
    "        # Numerical processing Neural Network\n",
    "        self.numerical_input = Input(shape=(num_numerical_features,))\n",
    "        numerical_processing_network = self.numerical_input\n",
    "        numerical_processing_network = Dense(64, activation='relu')(numerical_processing_network)\n",
    "        numerical_processing_network = Dense(64, activation='relu')(numerical_processing_network)\n",
    "\n",
    "        # Concatenation of both networks\n",
    "        aot_network = Concatenate()([image_processing_network, numerical_processing_network])\n",
    "        aot_network = Dense(64, activation='relu')(aot_network)\n",
    "        aot_network = Dense(1)(aot_network)\n",
    "\n",
    "        self.aot_network_arquitecture = aot_network\n",
    "        del image_processing_network, numerical_processing_network, aot_network\n",
    "\n",
    "    def model(self):\n",
    "        model = Model(inputs= [self.image_input, self.numerical_input], outputs=self.aot_network_arquitecture)\n",
    "        \n",
    "        # Compile the model\n",
    "        model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[14.01176471  9.82745098  9.05490196 ...  0.06666667 10.65490196\n",
      "    9.58431373]\n",
      "  [14.01176471  9.47058824  8.65882353 ...  0.06666667 11.11764706\n",
      "    9.69411765]\n",
      "  [14.01176471 10.3372549   9.78431373 ...  0.06666667 10.32941176\n",
      "    9.10588235]\n",
      "  ...\n",
      "  [16.37647059 12.78039216 11.81960784 ...  0.0627451   4.41176471\n",
      "    3.43529412]\n",
      "  [16.37647059 19.7254902  17.99607843 ...  0.0627451   3.36078431\n",
      "    2.60392157]\n",
      "  [16.06666667 20.3254902  19.67843137 ...  0.0627451   1.69019608\n",
      "    1.19607843]]\n",
      "\n",
      " [[14.01176471 13.15294118 12.29411765 ...  0.06666667  9.85098039\n",
      "    9.03137255]\n",
      "  [14.01176471 12.2745098  11.6627451  ...  0.06666667  8.51764706\n",
      "    8.02745098]\n",
      "  [14.01176471 14.54117647 14.0745098  ...  0.06666667  7.35294118\n",
      "    6.20392157]\n",
      "  ...\n",
      "  [16.37647059 15.1254902  14.02745098 ...  0.0627451   4.36078431\n",
      "    3.75294118]\n",
      "  [16.37647059 15.32941176 14.87058824 ...  0.0627451   3.81176471\n",
      "    3.27058824]\n",
      "  [16.06666667 20.61568627 19.84705882 ...  0.0627451   2.9254902\n",
      "    2.38823529]]\n",
      "\n",
      " [[14.01176471 16.34901961 15.78823529 ...  0.06666667  8.61176471\n",
      "    7.20392157]\n",
      "  [14.01176471 16.85098039 16.03137255 ...  0.06666667  5.90588235\n",
      "    5.05098039]\n",
      "  [14.01176471 15.74901961 15.82745098 ...  0.06666667  4.29411765\n",
      "    3.7372549 ]\n",
      "  ...\n",
      "  [16.37647059 19.18039216 17.94509804 ...  0.0627451   2.9372549\n",
      "    2.47843137]\n",
      "  [16.37647059 22.63921569 21.68235294 ...  0.0627451   3.65490196\n",
      "    2.91372549]\n",
      "  [16.06666667 18.68235294 17.69411765 ...  0.0627451   5.58431373\n",
      "    4.81176471]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[18.53333333 16.25490196 15.07843137 ...  0.04705882  2.6627451\n",
      "    1.94509804]\n",
      "  [18.53333333 21.32941176 19.18823529 ...  0.04705882  1.19215686\n",
      "    0.87843137]\n",
      "  [18.53333333 19.33333333 16.73333333 ...  0.04705882  0.80784314\n",
      "    0.65882353]\n",
      "  ...\n",
      "  [16.27843137 17.23529412 16.46666667 ...  0.0627451   5.32941176\n",
      "    4.78039216]\n",
      "  [16.27843137 12.38823529 11.2745098  ...  0.0627451   7.41960784\n",
      "    6.28235294]\n",
      "  [14.54117647 10.31764706  9.84705882 ...  0.07058824  7.72941176\n",
      "    6.69411765]]\n",
      "\n",
      " [[18.53333333 18.72941176 17.50588235 ...  0.04705882  3.19215686\n",
      "    2.61176471]\n",
      "  [18.53333333 20.12941176 17.95294118 ...  0.04705882  1.45490196\n",
      "    0.92156863]\n",
      "  [18.53333333 17.85098039 15.52156863 ...  0.04705882  0.97647059\n",
      "    0.72156863]\n",
      "  ...\n",
      "  [16.27843137 19.2627451  17.93333333 ...  0.0627451   4.18431373\n",
      "    3.58039216]\n",
      "  [16.27843137 12.17647059 11.39215686 ...  0.0627451   7.19215686\n",
      "    6.38823529]\n",
      "  [14.54117647  9.6627451   8.97254902 ...  0.07058824  9.60784314\n",
      "    8.64705882]]\n",
      "\n",
      " [[19.89019608 17.67843137 16.75294118 ...  0.05490196  2.91372549\n",
      "    2.44313725]\n",
      "  [19.89019608 17.72941176 16.74509804 ...  0.05490196  2.10196078\n",
      "    1.70196078]\n",
      "  [19.89019608 17.41960784 16.30196078 ...  0.05490196  1.79215686\n",
      "    1.44313725]\n",
      "  ...\n",
      "  [13.24313725 19.56470588 18.52156863 ...  0.0745098   3.81176471\n",
      "    3.15294118]\n",
      "  [13.24313725 13.71764706 12.36078431 ...  0.0745098   5.01568627\n",
      "    4.16470588]\n",
      "  [11.93333333 11.82745098 11.00784314 ...  0.07058824  6.42352941\n",
      "    5.5254902 ]]]\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer \"functional_7\" is incompatible with the layer: expected shape=(None, 19, 19, 3), found shape=(None, 19, 19, 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(X_train_img[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_train_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_num\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_val_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val_num\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[1;32m      9\u001b[0m val_loss, val_mae \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate([X_val_img, X_val_num], y_val)\n",
      "File \u001b[0;32m~/Aerosol_prediction_neural_network/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Aerosol_prediction_neural_network/.venv/lib/python3.10/site-packages/keras/src/layers/input_spec.py:245\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec_dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m spec_dim \u001b[38;5;241m!=\u001b[39m dim:\n\u001b[0;32m--> 245\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    246\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    247\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible with the layer: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    248\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspec\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    249\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    250\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 of layer \"functional_7\" is incompatible with the layer: expected shape=(None, 19, 19, 3), found shape=(None, 19, 19, 13)"
     ]
    }
   ],
   "source": [
    "model = AOTModel()\n",
    "model = model.model()\n",
    "\n",
    "print(X_train_img[0])\n",
    "# Train the model\n",
    "history = model.fit([X_train_img, X_train_num], y_train, validation_data=([X_val_img, X_val_num], y_val), epochs=50, batch_size=32)\n",
    "\n",
    "# Evaluate the model\n",
    "val_loss, val_mae = model.evaluate([X_val_img, X_val_num], y_val)\n",
    "print(f'Validation MAE: {val_mae}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
